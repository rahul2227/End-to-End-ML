{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basic_text_generation_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhFMVzf3bkp3"
      },
      "source": [
        "#importing libraries\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Other imports for processing data\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofFVa4xsb4XO",
        "outputId": "8ec78ef8-d405-4276-880a-4c7351b96073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
        "    -O /tmp/songdata.csv"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-29 05:57:25--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.20.139, 74.125.20.138, 74.125.20.101, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.20.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/kk3nsnt2b3tc10gp625p5ahotbosvk1k/1601358975000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-09-29 05:57:28--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/kk3nsnt2b3tc10gp625p5ahotbosvk1k/1601358975000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 74.125.195.132, 2607:f8b0:400e:c09::84\n",
            "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|74.125.195.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/csv]\n",
            "Saving to: ‘/tmp/songdata.csv’\n",
            "\n",
            "/tmp/songdata.csv       [   <=>              ]  69.08M   109MB/s    in 0.6s    \n",
            "\n",
            "2020-09-29 05:57:29 (109 MB/s) - ‘/tmp/songdata.csv’ saved [72436445]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rMb5v37b9pS"
      },
      "source": [
        "#preprocessing\n",
        "\n",
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "def create_lyrics_corpus(dataset, field):\n",
        "  # Remove all other punctuation\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  # Make it lowercase\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "  # Make it one long string to split by line\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "  # Remove any trailing whitespace\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "  # Remove any empty lines\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eU7HcP3GcB6K",
        "outputId": "d62f2ea6-5ec3-45be-d000-8dcf340946f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Read the dataset from csv - just first 10 songs for now\n",
        "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:10]\n",
        "# Create the corpus using the 'text' column containing lyrics\n",
        "corpus = create_lyrics_corpus(dataset, 'text')\n",
        "# Tokenize the corpus\n",
        "tokenizer = tokenize_corpus(corpus)\n",
        "\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "print(tokenizer.word_index)\n",
        "print(total_words)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'you': 1, 'i': 2, 'and': 3, 'a': 4, 'me': 5, 'the': 6, 'is': 7, 'my': 8, 'to': 9, 'ma': 10, 'it': 11, 'of': 12, 'im': 13, 'your': 14, 'love': 15, 'so': 16, 'as': 17, 'that': 18, 'in': 19, 'andante': 20, 'boomaboomerang': 21, 'make': 22, 'on': 23, 'oh': 24, 'for': 25, 'but': 26, 'new': 27, 'bang': 28, 'its': 29, 'be': 30, 'like': 31, 'know': 32, 'now': 33, 'how': 34, 'could': 35, 'youre': 36, 'sing': 37, 'never': 38, 'no': 39, 'chiquitita': 40, 'can': 41, 'we': 42, 'song': 43, 'had': 44, 'good': 45, 'youll': 46, 'she': 47, 'just': 48, 'girl': 49, 'again': 50, 'will': 51, 'take': 52, 'please': 53, 'let': 54, 'am': 55, 'eyes': 56, 'was': 57, 'always': 58, 'cassandra': 59, 'blue': 60, 'time': 61, 'dont': 62, 'were': 63, 'return': 64, 'once': 65, 'then': 66, 'sorry': 67, 'cryin': 68, 'over': 69, 'feel': 70, 'ever': 71, 'believe': 72, 'what': 73, 'do': 74, 'go': 75, 'all': 76, 'out': 77, 'think': 78, 'every': 79, 'leave': 80, 'look': 81, 'at': 82, 'way': 83, 'one': 84, 'music': 85, 'down': 86, 'our': 87, 'give': 88, 'learn': 89, 'more': 90, 'us': 91, 'would': 92, 'there': 93, 'before': 94, 'when': 95, 'with': 96, 'feeling': 97, 'play': 98, 'cause': 99, 'away': 100, 'here': 101, 'have': 102, 'yes': 103, 'baby': 104, 'get': 105, 'didnt': 106, 'see': 107, 'did': 108, 'closed': 109, 'realized': 110, 'crazy': 111, 'world': 112, 'lord': 113, 'shes': 114, 'kind': 115, 'without': 116, 'if': 117, 'touch': 118, 'strong': 119, 'making': 120, 'such': 121, 'found': 122, 'true': 123, 'stay': 124, 'together': 125, 'thought': 126, 'come': 127, 'they': 128, 'sweet': 129, 'tender': 130, 'sender': 131, 'tune': 132, 'humdehumhum': 133, 'gonna': 134, 'last': 135, 'leaving': 136, 'sleep': 137, 'only': 138, 'saw': 139, 'tell': 140, 'hes': 141, 'her': 142, 'sound': 143, 'tread': 144, 'lightly': 145, 'ground': 146, 'ill': 147, 'show': 148, 'life': 149, 'too': 150, 'used': 151, 'darling': 152, 'meant': 153, 'break': 154, 'end': 155, 'yourself': 156, 'little': 157, 'dumbedumdum': 158, 'bedumbedumdum': 159, 'youve': 160, 'dumbbedumbdumb': 161, 'bedumbbedumbdumb': 162, 'by': 163, 'theyre': 164, 'alone': 165, 'misunderstood': 166, 'day': 167, 'dawning': 168, 'some': 169, 'wanted': 170, 'none': 171, 'listen': 172, 'words': 173, 'warning': 174, 'darkest': 175, 'nights': 176, 'nobody': 177, 'knew': 178, 'fight': 179, 'caught': 180, 'really': 181, 'power': 182, 'dreams': 183, 'weave': 184, 'until': 185, 'final': 186, 'hour': 187, 'morning': 188, 'ship': 189, 'gone': 190, 'grieving': 191, 'still': 192, 'pain': 193, 'cry': 194, 'sun': 195, 'try': 196, 'face': 197, 'something': 198, 'sees': 199, 'makes': 200, 'fine': 201, 'who': 202, 'mine': 203, 'leaves': 204, 'walk': 205, 'hand': 206, 'well': 207, 'about': 208, 'things': 209, 'slow': 210, 'theres': 211, 'talk': 212, 'why': 213, 'up': 214, 'lousy': 215, 'packing': 216, 'ive': 217, 'gotta': 218, 'near': 219, 'keeping': 220, 'intention': 221, 'growing': 222, 'taking': 223, 'dimension': 224, 'even': 225, 'better': 226, 'thank': 227, 'god': 228, 'not': 229, 'somebody': 230, 'happy': 231, 'question': 232, 'smile': 233, 'mean': 234, 'much': 235, 'kisses': 236, 'around': 237, 'anywhere': 238, 'advice': 239, 'care': 240, 'use': 241, 'selfish': 242, 'tool': 243, 'fool': 244, 'showing': 245, 'boomerang': 246, 'throwing': 247, 'warm': 248, 'kiss': 249, 'surrender': 250, 'giving': 251, 'been': 252, 'door': 253, 'burning': 254, 'bridges': 255, 'being': 256, 'moving': 257, 'though': 258, 'behind': 259, 'are': 260, 'must': 261, 'sure': 262, 'stood': 263, 'hope': 264, 'this': 265, 'deny': 266, 'sad': 267, 'quiet': 268, 'truth': 269, 'heartaches': 270, 'scars': 271, 'dancing': 272, 'sky': 273, 'shining': 274, 'above': 275, 'hear': 276, 'came': 277, 'couldnt': 278, 'everything': 279, 'back': 280, 'long': 281, 'waitin': 282, 'cold': 283, 'chills': 284, 'bone': 285, 'youd': 286, 'wonderful': 287, 'means': 288, 'special': 289, 'smiles': 290, 'lucky': 291, 'fellow': 292, 'park': 293, 'holds': 294, 'squeezes': 295, 'walking': 296, 'hours': 297, 'talking': 298, 'plan': 299, 'easy': 300, 'gently': 301, 'summer': 302, 'evening': 303, 'breeze': 304, 'grow': 305, 'fingers': 306, 'soft': 307, 'light': 308, 'body': 309, 'velvet': 310, 'night': 311, 'soul': 312, 'slowly': 313, 'shimmer': 314, 'thousand': 315, 'butterflies': 316, 'float': 317, 'put': 318, 'rotten': 319, 'boy': 320, 'tough': 321, 'stuff': 322, 'saying': 323, 'need': 324, 'anymore': 325, 'enough': 326, 'standing': 327, 'creep': 328, 'felt': 329, 'cheap': 330, 'notion': 331, 'deep': 332, 'dumb': 333, 'mistake': 334, 'entitled': 335, 'another': 336, 'beg': 337, 'forgive': 338, 'an': 339, 'feels': 340, 'hoot': 341, 'holler': 342, 'mad': 343, 'under': 344, 'heel': 345, 'holy': 346, 'christ': 347, 'deal': 348, 'sick': 349, 'tired': 350, 'tedious': 351, 'ways': 352, 'aint': 353, 'walkin': 354, 'cutting': 355, 'tie': 356, 'wanna': 357, 'into': 358, 'eye': 359, 'myself': 360, 'counting': 361, 'pride': 362, 'unright': 363, 'neighbours': 364, 'ride': 365, 'burying': 366, 'past': 367, 'peace': 368, 'free': 369, 'sucker': 370, 'street': 371, 'singing': 372, 'shouting': 373, 'staying': 374, 'alive': 375, 'city': 376, 'dead': 377, 'hiding': 378, 'their': 379, 'shame': 380, 'hollow': 381, 'laughter': 382, 'while': 383, 'crying': 384, 'bed': 385, 'pity': 386, 'believed': 387, 'lost': 388, 'from': 389, 'start': 390, 'suffer': 391, 'sell': 392, 'secrets': 393, 'bargain': 394, 'playing': 395, 'smart': 396, 'aching': 397, 'hearts': 398, 'sailing': 399, 'father': 400, 'sister': 401, 'reason': 402, 'linger': 403, 'deeply': 404, 'future': 405, 'casting': 406, 'shadow': 407, 'else': 408, 'fate': 409, 'bags': 410, 'thorough': 411, 'knowing': 412, 'late': 413, 'wait': 414, 'watched': 415, 'harbor': 416, 'sunrise': 417, 'sails': 418, 'almost': 419, 'slack': 420, 'cool': 421, 'rain': 422, 'deck': 423, 'tiny': 424, 'figure': 425, 'rigid': 426, 'restrained': 427, 'filled': 428, 'whats': 429, 'wrong': 430, 'enchained': 431, 'own': 432, 'sorrow': 433, 'tomorrow': 434, 'hate': 435, 'shoulder': 436, 'best': 437, 'friend': 438, 'rely': 439, 'broken': 440, 'feather': 441, 'patch': 442, 'walls': 443, 'tumbling': 444, 'loves': 445, 'blown': 446, 'candle': 447, 'seems': 448, 'hard': 449, 'handle': 450, 'id': 451, 'thinking': 452, 'went': 453, 'house': 454, 'hardly': 455, 'guy': 456, 'closing': 457, 'front': 458, 'emptiness': 459, 'he': 460, 'disapeared': 461, 'his': 462, 'car': 463, 'stunned': 464, 'dreamed': 465, 'lifes': 466, 'part': 467, 'move': 468, 'feet': 469, 'pavement': 470, 'acted': 471, 'told': 472, 'lies': 473, 'meet': 474, 'other': 475, 'guys': 476, 'stupid': 477, 'blind': 478, 'smiled': 479, 'took': 480, 'said': 481, 'may': 482, 'couple': 483, 'men': 484, 'them': 485, 'brother': 486, 'joe': 487, 'seeing': 488, 'lot': 489, 'him': 490, 'nice': 491, 'sitting': 492, 'sittin': 493, 'memories': 494}\n",
            "495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7DqGWxfcDnC"
      },
      "source": [
        "#creating sequence and labels\n",
        "#including use of n-grams techniquw for creating one-hot encoding\n",
        "sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length \n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "# One-hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPqft2hjcTCp",
        "outputId": "6c3a5bbb-97ee-4d4c-ed99-2475feed3a10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "# Check out how some of our data is being stored\n",
        "# The Tokenizer has just a single index per word\n",
        "print(tokenizer.word_index['know'])\n",
        "print(tokenizer.word_index['feeling'])\n",
        "# Input sequences will have multiple indexes\n",
        "print(input_sequences[5])\n",
        "print(input_sequences[6])\n",
        "# And the one hot labels will be as long as the full spread of tokenized words\n",
        "print(one_hot_labels[5])\n",
        "print(one_hot_labels[6])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "97\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29\n",
            "   4]\n",
            "[  0   0   0   0   0   0   0   0   0   0   0   0  81  82 142 197  29   4\n",
            " 287]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI8tM5x2cW7q",
        "outputId": "280e2d54-4ac1-41ee-8355-e7e04de9f1a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#model for generating text using RNN \n",
        "#changing loss function to categorical-crossentropy from binary as we are\n",
        "#having multiple output classes\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=200, verbose=1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 5.9889 - accuracy: 0.0237\n",
            "Epoch 2/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 5.4392 - accuracy: 0.0383\n",
            "Epoch 3/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 5.3665 - accuracy: 0.0373\n",
            "Epoch 4/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 5.3114 - accuracy: 0.0399\n",
            "Epoch 5/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 5.2422 - accuracy: 0.0394\n",
            "Epoch 6/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 5.1749 - accuracy: 0.0399\n",
            "Epoch 7/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 5.1146 - accuracy: 0.0368\n",
            "Epoch 8/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 5.0491 - accuracy: 0.0459\n",
            "Epoch 9/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.9767 - accuracy: 0.0560\n",
            "Epoch 10/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 4.8968 - accuracy: 0.0600\n",
            "Epoch 11/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.8242 - accuracy: 0.0671\n",
            "Epoch 12/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.7492 - accuracy: 0.0802\n",
            "Epoch 13/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.6671 - accuracy: 0.0928\n",
            "Epoch 14/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 4.5877 - accuracy: 0.0994\n",
            "Epoch 15/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.5215 - accuracy: 0.1150\n",
            "Epoch 16/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 4.4457 - accuracy: 0.1226\n",
            "Epoch 17/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 4.3609 - accuracy: 0.1403\n",
            "Epoch 18/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 4.2878 - accuracy: 0.1504\n",
            "Epoch 19/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 4.2192 - accuracy: 0.1584\n",
            "Epoch 20/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 4.1351 - accuracy: 0.1756\n",
            "Epoch 21/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.0702 - accuracy: 0.1897\n",
            "Epoch 22/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 4.0039 - accuracy: 0.1998\n",
            "Epoch 23/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.9349 - accuracy: 0.1993\n",
            "Epoch 24/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 3.8655 - accuracy: 0.2129\n",
            "Epoch 25/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 3.7933 - accuracy: 0.2190\n",
            "Epoch 26/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.7321 - accuracy: 0.2255\n",
            "Epoch 27/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.6663 - accuracy: 0.2397\n",
            "Epoch 28/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.6185 - accuracy: 0.2497\n",
            "Epoch 29/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 3.5518 - accuracy: 0.2669\n",
            "Epoch 30/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.4888 - accuracy: 0.2830\n",
            "Epoch 31/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.4240 - accuracy: 0.2916\n",
            "Epoch 32/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 3.3523 - accuracy: 0.3052\n",
            "Epoch 33/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.3008 - accuracy: 0.3209\n",
            "Epoch 34/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.2368 - accuracy: 0.3199\n",
            "Epoch 35/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.1843 - accuracy: 0.3496\n",
            "Epoch 36/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 3.1244 - accuracy: 0.3602\n",
            "Epoch 37/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 3.0681 - accuracy: 0.3754\n",
            "Epoch 38/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 3.0119 - accuracy: 0.3935\n",
            "Epoch 39/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.9543 - accuracy: 0.4016\n",
            "Epoch 40/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.9094 - accuracy: 0.4057\n",
            "Epoch 41/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.8648 - accuracy: 0.4142\n",
            "Epoch 42/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.8090 - accuracy: 0.4253\n",
            "Epoch 43/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.7550 - accuracy: 0.4314\n",
            "Epoch 44/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.7004 - accuracy: 0.4511\n",
            "Epoch 45/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.6574 - accuracy: 0.4571\n",
            "Epoch 46/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.6111 - accuracy: 0.4778\n",
            "Epoch 47/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.5700 - accuracy: 0.4828\n",
            "Epoch 48/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.5187 - accuracy: 0.4854\n",
            "Epoch 49/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.4680 - accuracy: 0.5005\n",
            "Epoch 50/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.4330 - accuracy: 0.5040\n",
            "Epoch 51/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.3829 - accuracy: 0.5146\n",
            "Epoch 52/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.3512 - accuracy: 0.5197\n",
            "Epoch 53/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.3034 - accuracy: 0.5247\n",
            "Epoch 54/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.2661 - accuracy: 0.5298\n",
            "Epoch 55/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.2146 - accuracy: 0.5394\n",
            "Epoch 56/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.1765 - accuracy: 0.5540\n",
            "Epoch 57/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.1392 - accuracy: 0.5575\n",
            "Epoch 58/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.1080 - accuracy: 0.5626\n",
            "Epoch 59/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 2.0703 - accuracy: 0.5661\n",
            "Epoch 60/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.0406 - accuracy: 0.5737\n",
            "Epoch 61/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 2.0239 - accuracy: 0.5727\n",
            "Epoch 62/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.9860 - accuracy: 0.5762\n",
            "Epoch 63/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.9425 - accuracy: 0.5888\n",
            "Epoch 64/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.9058 - accuracy: 0.5964\n",
            "Epoch 65/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.8724 - accuracy: 0.6115\n",
            "Epoch 66/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.8411 - accuracy: 0.6120\n",
            "Epoch 67/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.8075 - accuracy: 0.6160\n",
            "Epoch 68/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.7723 - accuracy: 0.6266\n",
            "Epoch 69/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.7442 - accuracy: 0.6347\n",
            "Epoch 70/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.7289 - accuracy: 0.6337\n",
            "Epoch 71/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.7123 - accuracy: 0.6342\n",
            "Epoch 72/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.6868 - accuracy: 0.6322\n",
            "Epoch 73/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.6481 - accuracy: 0.6509\n",
            "Epoch 74/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.6247 - accuracy: 0.6589\n",
            "Epoch 75/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5889 - accuracy: 0.6594\n",
            "Epoch 76/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5617 - accuracy: 0.6700\n",
            "Epoch 77/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5421 - accuracy: 0.6690\n",
            "Epoch 78/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5297 - accuracy: 0.6660\n",
            "Epoch 79/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.5251 - accuracy: 0.6751\n",
            "Epoch 80/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4920 - accuracy: 0.6857\n",
            "Epoch 81/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4708 - accuracy: 0.6882\n",
            "Epoch 82/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4445 - accuracy: 0.6932\n",
            "Epoch 83/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.4217 - accuracy: 0.6948\n",
            "Epoch 84/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3977 - accuracy: 0.7074\n",
            "Epoch 85/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3921 - accuracy: 0.7059\n",
            "Epoch 86/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3611 - accuracy: 0.7134\n",
            "Epoch 87/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.3372 - accuracy: 0.7094\n",
            "Epoch 88/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.3091 - accuracy: 0.7230\n",
            "Epoch 89/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.2835 - accuracy: 0.7286\n",
            "Epoch 90/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.2731 - accuracy: 0.7311\n",
            "Epoch 91/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2486 - accuracy: 0.7397\n",
            "Epoch 92/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2343 - accuracy: 0.7386\n",
            "Epoch 93/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.2369 - accuracy: 0.7381\n",
            "Epoch 94/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.2425 - accuracy: 0.7341\n",
            "Epoch 95/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1967 - accuracy: 0.7508\n",
            "Epoch 96/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1835 - accuracy: 0.7503\n",
            "Epoch 97/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1709 - accuracy: 0.7518\n",
            "Epoch 98/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1562 - accuracy: 0.7568\n",
            "Epoch 99/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1345 - accuracy: 0.7568\n",
            "Epoch 100/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1409 - accuracy: 0.7482\n",
            "Epoch 101/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.1207 - accuracy: 0.7558\n",
            "Epoch 102/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0987 - accuracy: 0.7598\n",
            "Epoch 103/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0828 - accuracy: 0.7704\n",
            "Epoch 104/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.0727 - accuracy: 0.7659\n",
            "Epoch 105/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0834 - accuracy: 0.7669\n",
            "Epoch 106/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0552 - accuracy: 0.7714\n",
            "Epoch 107/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0629 - accuracy: 0.7644\n",
            "Epoch 108/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 1.0212 - accuracy: 0.7805\n",
            "Epoch 109/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 1.0098 - accuracy: 0.7790\n",
            "Epoch 110/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9880 - accuracy: 0.7820\n",
            "Epoch 111/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9710 - accuracy: 0.7891\n",
            "Epoch 112/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.9640 - accuracy: 0.7891\n",
            "Epoch 113/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9489 - accuracy: 0.7891\n",
            "Epoch 114/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9421 - accuracy: 0.7941\n",
            "Epoch 115/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9245 - accuracy: 0.7977\n",
            "Epoch 116/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.9193 - accuracy: 0.7921\n",
            "Epoch 117/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9190 - accuracy: 0.7931\n",
            "Epoch 118/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9133 - accuracy: 0.7896\n",
            "Epoch 119/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.9030 - accuracy: 0.7952\n",
            "Epoch 120/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8914 - accuracy: 0.7941\n",
            "Epoch 121/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.8822 - accuracy: 0.7926\n",
            "Epoch 122/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.8598 - accuracy: 0.8037\n",
            "Epoch 123/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8519 - accuracy: 0.8063\n",
            "Epoch 124/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.8348 - accuracy: 0.8083\n",
            "Epoch 125/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8220 - accuracy: 0.8083\n",
            "Epoch 126/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8096 - accuracy: 0.8108\n",
            "Epoch 127/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.8066 - accuracy: 0.8103\n",
            "Epoch 128/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7930 - accuracy: 0.8214\n",
            "Epoch 129/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7903 - accuracy: 0.8133\n",
            "Epoch 130/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7792 - accuracy: 0.8209\n",
            "Epoch 131/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7822 - accuracy: 0.8153\n",
            "Epoch 132/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.7746 - accuracy: 0.8234\n",
            "Epoch 133/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7594 - accuracy: 0.8209\n",
            "Epoch 134/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7435 - accuracy: 0.8259\n",
            "Epoch 135/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7347 - accuracy: 0.8285\n",
            "Epoch 136/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7252 - accuracy: 0.8340\n",
            "Epoch 137/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7173 - accuracy: 0.8295\n",
            "Epoch 138/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7146 - accuracy: 0.8365\n",
            "Epoch 139/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7167 - accuracy: 0.8335\n",
            "Epoch 140/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7217 - accuracy: 0.8335\n",
            "Epoch 141/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7141 - accuracy: 0.8244\n",
            "Epoch 142/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7085 - accuracy: 0.8320\n",
            "Epoch 143/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.7230 - accuracy: 0.8290\n",
            "Epoch 144/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6929 - accuracy: 0.8370\n",
            "Epoch 145/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6746 - accuracy: 0.8391\n",
            "Epoch 146/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6630 - accuracy: 0.8436\n",
            "Epoch 147/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6705 - accuracy: 0.8421\n",
            "Epoch 148/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.6659 - accuracy: 0.8380\n",
            "Epoch 149/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6624 - accuracy: 0.8370\n",
            "Epoch 150/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6599 - accuracy: 0.8491\n",
            "Epoch 151/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6436 - accuracy: 0.8451\n",
            "Epoch 152/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6288 - accuracy: 0.8512\n",
            "Epoch 153/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6214 - accuracy: 0.8491\n",
            "Epoch 154/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6151 - accuracy: 0.8567\n",
            "Epoch 155/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6058 - accuracy: 0.8517\n",
            "Epoch 156/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6285 - accuracy: 0.8476\n",
            "Epoch 157/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6093 - accuracy: 0.8532\n",
            "Epoch 158/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5948 - accuracy: 0.8572\n",
            "Epoch 159/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5884 - accuracy: 0.8648\n",
            "Epoch 160/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5797 - accuracy: 0.8602\n",
            "Epoch 161/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5728 - accuracy: 0.8643\n",
            "Epoch 162/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5646 - accuracy: 0.8658\n",
            "Epoch 163/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5619 - accuracy: 0.8678\n",
            "Epoch 164/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5770 - accuracy: 0.8623\n",
            "Epoch 165/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5827 - accuracy: 0.8557\n",
            "Epoch 166/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5560 - accuracy: 0.8643\n",
            "Epoch 167/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5553 - accuracy: 0.8678\n",
            "Epoch 168/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5517 - accuracy: 0.8713\n",
            "Epoch 169/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5457 - accuracy: 0.8673\n",
            "Epoch 170/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5372 - accuracy: 0.8628\n",
            "Epoch 171/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5274 - accuracy: 0.8724\n",
            "Epoch 172/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5214 - accuracy: 0.8713\n",
            "Epoch 173/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5145 - accuracy: 0.8744\n",
            "Epoch 174/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5059 - accuracy: 0.8759\n",
            "Epoch 175/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5023 - accuracy: 0.8759\n",
            "Epoch 176/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4991 - accuracy: 0.8764\n",
            "Epoch 177/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.5096 - accuracy: 0.8729\n",
            "Epoch 178/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4960 - accuracy: 0.8774\n",
            "Epoch 179/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4942 - accuracy: 0.8779\n",
            "Epoch 180/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4889 - accuracy: 0.8819\n",
            "Epoch 181/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4856 - accuracy: 0.8799\n",
            "Epoch 182/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4771 - accuracy: 0.8809\n",
            "Epoch 183/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4714 - accuracy: 0.8824\n",
            "Epoch 184/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4692 - accuracy: 0.8870\n",
            "Epoch 185/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4610 - accuracy: 0.8829\n",
            "Epoch 186/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4559 - accuracy: 0.8829\n",
            "Epoch 187/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4541 - accuracy: 0.8789\n",
            "Epoch 188/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4572 - accuracy: 0.8814\n",
            "Epoch 189/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4839 - accuracy: 0.8749\n",
            "Epoch 190/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4697 - accuracy: 0.8774\n",
            "Epoch 191/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4675 - accuracy: 0.8774\n",
            "Epoch 192/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5028 - accuracy: 0.8673\n",
            "Epoch 193/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4783 - accuracy: 0.8739\n",
            "Epoch 194/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4580 - accuracy: 0.8759\n",
            "Epoch 195/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4548 - accuracy: 0.8769\n",
            "Epoch 196/200\n",
            "62/62 [==============================] - 0s 6ms/step - loss: 0.4640 - accuracy: 0.8769\n",
            "Epoch 197/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.6197 - accuracy: 0.8370\n",
            "Epoch 198/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5571 - accuracy: 0.8436\n",
            "Epoch 199/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.5519 - accuracy: 0.8436\n",
            "Epoch 200/200\n",
            "62/62 [==============================] - 0s 7ms/step - loss: 0.4853 - accuracy: 0.8698\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kBQ8PhMcr-a",
        "outputId": "c1973fdb-5d99-4ceb-faab-597c863a1935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "#the training graph\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gYHpoq9cxkR",
        "outputId": "a3c5bad3-7208-4848-b8a6-f4ba57f2ed49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#generation of new song lyrics as we by taking kaggle song corpus as base\n",
        "seed_text = \"im feeling chills\"#initial starting argument\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "im feeling chills and you make me sing once your father and more something special to i oh i christ cheap cheap only almost shadow sky wanted us sorrow morning realized crazy crazy wonderful lightly bang wanted its yourself a break none chiquitita realized misunderstood realized take found have have have for cause youre andante andante andante making me bang a crazy question crazy world sleep crazy hour shoulder chiquitita making new its do on used crazy crazy world crazy wonderful bed rotten realized misunderstood misunderstood realized crazy hour tune realized crazy crazy world shoulder new crazy world soul crazy kisses fight world\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ceKVsPnc-Ix"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}